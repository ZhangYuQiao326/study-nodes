数据科学相关岗位的薪资水平

# 一 需求分析

# 二 数据采集

```py
import requests
from lxml import etree
import xlwt

# 拿到源代码
job = {}
jobs = []
parser = etree.HTMLParser(encoding="utf8") # 定义解析器
html = etree.parse(r"C:\Users\zhang\Desktop\机器学习\深度学习算法工程师7.html", parser=parser) # 使用自己的解析器进行解析
# 测试代码：是否拿到含有数据的网页源代码
# print(etree.tostring(html, encoding="utf8").decode("utf8"))
# 拿到所有的（小窗口）
job_informations = html.xpath('//*[@id="jobList"]/div[1]/div')
for job_information in job_informations:
    job_name = job_information.xpath('./div[1]/div[1]/div[1]/a/text()[1]')[0]
    job_company = job_information.xpath('.//div[1]/div[2]/div[1]/a/text()')[0]
    job_salary = job_information.xpath('./div[1]/div[1]/div[2]/span/text()')[0]
    job_degree = job_information.xpath('./div[1]/div[1]/div[2]/text()')[0]
    job_company_info = job_information.xpath('./div[1]/div[2]/div[2]/text()')[0]
    job_need = job_information.xpath('./div[2]/div[1]/span/text()')[0]
    job_walfare = job_information.xpath('./div[2]/div[2]/text()')[0]
    job = {
        "工作岗位":job_name,
        "公司":job_company,
        "薪资":job_salary,
        "经验学历":job_degree,
        "公司信息":job_company_info,
        "所属行业":job_need,
        "福利":job_walfare,
    }
    jobs.append(job)
    # 测试代码：是否获取数据
    # print(job_name, job_company, job_salary, job_degree, job_company_info)

# 保存数据
workbook = xlwt.Workbook(encoding="utf8")
# 1.(修改)sheet名字
sheet = workbook.add_sheet("sheet")
# 2.(修改all)取出all中的第一个one对象的键名，并强制转存为列表中，作为小标题
keys = list(jobs[0].keys())
for i in range(len(keys)):
    sheet.write(0, i, keys[i])
# 3.（修改all）从第二行开始存入内容
for row in range(1, len(jobs)+1, 1):
    for col, key in zip(range(len(keys)), keys):
        sheet.write(row, col, jobs[row - 1][key])

# 4.(修改保存路径和文件名)保存excel
workbook.save(r"C:\Users\zhang\Desktop\深度学习算法工程师7.xls")

###用于写论文的代码

import requests
from lxml import etree
import pandas as pd
from time import sleep
import random

def static_crawl():
    cookie = 'll="118318"; bid=tTAAlioHk_Q; __utmz=30149280.1670315049.1.1.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; ap_v=0,6.0; __utma=30149280.752377764.1670315049.1670315049.1671499381.2; __utmb=30149280.0.10.1671499381; __utmc=30149280'
    headers = {
        'cookie':cookie,
        'User-Agent':"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
        }
    for i in range(1, 7):
        sleep(random.randint(3, 10))
        url = 'https://www.lagou.com/zhaopin/jiqixuexi/{}/?filterOption=3'.format(i)
        print('正在抓取第{}页...'.format(i), url)
        con = etree.HTML(requests.get(url=url, headers=headers).text)

    job_informations = html.xpath('//*[@id="jobList"]/div[1]/div')
    for job_information in job_informations:
        job_name = job_information.xpath('./div[1]/div[1]/div[1]/a/text()[1]')[0]
        job_company = job_information.xpath('.//div[1]/div[2]/div[1]/a/text()')[0]
        job_salary = job_information.xpath('./div[1]/div[1]/div[2]/span/text()')[0]
        job_degree = job_information.xpath('./div[1]/div[1]/div[2]/text()')[0]
        job_company_info = job_information.xpath('./div[1]/div[2]/div[2]/text()')[0]
        job_need = job_information.xpath('./div[2]/div[1]/span/text()')[0]
        job_walfare = job_information.xpath('./div[2]/div[2]/text()')[0]
        job = {
            "工作岗位":job_name,
            "公司":job_company,
            "薪资":job_salary,
            "经验学历":job_degree,
            "公司信息":job_company_info,
            "所属行业":job_need,
            "福利":job_walfare,
        }
        jobs.append(job)
        # 测试代码：是否获取数据
        # print(job_name, job_company, job_salary, job_degree, job_company_info)

    # 保存数据
    workbook = xlwt.Workbook(encoding="utf8")
    # 1.(修改)sheet名字
    sheet = workbook.add_sheet("sheet")
    # 2.(修改all)取出all中的第一个one对象的键名，并强制转存为列表中，作为小标题
    keys = list(jobs[0].keys())
    for i in range(len(keys)):
        sheet.write(0, i, keys[i])
    # 3.（修改all）从第二行开始存入内容
    for row in range(1, len(jobs)+1, 1):
        for col, key in zip(range(len(keys)), keys):
            sheet.write(row, col, jobs[row - 1][key])

    # 4.(修改保存路径和文件名)保存excel
    workbook.save(r"C:\Users\zhang\Desktop\data1.xls")

        return crawl_data

```





# 三 数据清洗

```
excel处理表格
```

```PY
import numpy as np
import pandas as pd
import string
import warnings
warnings.filterwarnings('ignore')

class data_clean(object):
    def __init__(self):
        pass
    
    def get_data(self):
        data1 = pd.read_csv('./data_analysis.csv', encoding='gbk')
        data2 = pd.read_csv('./machine_learning.csv', encoding='gbk')
        data3 = pd.read_csv('./data_mining.csv', encoding='gbk')
        data4 = pd.read_csv('./deep_learning.csv', encoding='gbk')

        data = pd.concat((pd.concat((pd.concat((data1, data2)), data3)), data4)).reset_index(drop=True)
        return data

    def clean_operation(self):
        data = self.get_data()
        data['工作地址'] = data['工作地址'].fillna("['未知']")
        for i, j in enumerate(data['工作地址']):
            j = j.replace('[', '').replace(']', '')
            data['工作地址'][i] = j
            
        for i, j in enumerate(data['薪资']):
            j = j.replace('k', '').replace('K', '').replace('以上', '-0')
            j1 = int(j.split('-')[0])
            j2 = int(j.split('-')[1])
            j3 = 1/2 * (j1+j2)
            data['薪资'][i] = j3*1000
            
        for i, j in enumerate(data['福利']):
            j = j.replace('[', '').replace(']', '')
            data['福利'][i] = j
            
        for i, j in enumerate(data['岗位名称']):
            if '数据分析' in j:
                j = '数据分析师'
            if '数据挖掘' in j:
                j = '数据挖掘工程师'
            if '机器学习' in j:
                j = '机器学习算法工程师'
            if '深度学习' in j:
                j = '深度学习算法工程师'
            if '大数据开发' in j:
                j = '大数据工程师'
            if '大数据运维' in j:
                j = '大数据工程师'
            if '大数据处理' in j:
                j = '大数据工程师'
			data['岗位名称'][i] = j

        return data
    
opt = data_clean()
data = opt.clean_operation()
data.head()
```

```
统计各信息权重
```



# 四 数据分析与可视化

```
```



# 五 特征工程

# 六 机器学习建模与调优

# 七 模型结果展示与报告输出

