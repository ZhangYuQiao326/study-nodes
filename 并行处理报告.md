### 3

随机森林算法是一种基于树模型的集成学习算法，通过训练多棵决策树以获得最终的预测结果，并且 在训练过程中对输入特征和样本进行随机抽样，增加 了一定的随机性，避免了高相关性的特征在多次训练 中造成的干扰，因此具有较好的泛化能力。

然而，传统 随机森林算法没有对分类能力不同的决策树进行区分，导致分类能力好的决策树和分类能力不好的决策树具有相同的投票能力，而且在训练过程中需要生成 多棵决策树，导致算法的运行时间较长。

###4

结合相关学者们的成果和自己的实验研究，本文提出一种基于Spark加权投票的随机森林算法，通过计算随机森林中决策树的AUC值来为每棵决策树分配投票权重，提高随机森林算法的分类精度，并提出一种数据索引抽样表和随机特征索引表来减少Spark与磁盘数据交互的次数，加快随机森林算法的并行化进程，从而提高运行效率。

###5

随机森林算法原理如下：

采用 Bagging 抽 样的方法从原始数据集中随机地、有放回地抽取一定 数据组成若干训练子集，随机挑选特征属性来训练这 些子集得到相对应的决策树，然后将测试集分别导入 到决策树中得到对应分类结果，最后通过投票选出最 终分类结果

### 6

本次算法中用到的AUC计算方法和加权投票法如下，不多概述

###7

###8

实验中，通过vm模拟出四台虚拟机，其中3台作为Slaver计算节点，1台为Master主控节点

数据集为UCI下载的四个二分类数据集

####9

SP-RF算法在Spark框架上并行化运行的流程如图所示，整个流程可以分为Map和Reduce两个阶段。

在Map阶段主要是对原始数据和特征名称进行索引抽样，然后把对应的索引记录分别保存在两个data_RDD和feature_RDD中，当进程读到索引表里的记录时，再返回到原始数据集和特征数组里抽取训练数据和特征组存放到D_RDD和F_RDD中。

在Reduce阶段主要是将得到的D_RDD和F_RDD的数据和特征进行计算构建相应的决策树，并计算每棵决策树的AUC值作为加权投票的权重，组成一个随机森林，然后对导入的测试集进行分类，统计投票结果得到最终的分类结果。

###10

结果如下：

左图可以看出在 Spark 集群上 SP-ＲF 算法要 优于传统 ＲF 算法，特别是在第一个和第三个 数据 集上提升较为明显，这是因为传统随机森林算法在这两个数据集上分类精度还有较大提升空 间，因此经过加权投票后的效果较好。

右图 可以看 出，SP-ＲF 算法在各个数据集上的运行时间较传统 ＲF 算法均有较大减少，这是因为经过优化后的 SP-ＲF 算 法减少了 Spark 进程等待的时间

### 11

这个实验结果图为SP-ＲF 算法在 Python 平台和 Spark 平台上 的运行时间对比，可以看出 SP-ＲF 算法在 Spark 平台 上的运行时间要远低于 Python 平台，主要是因为其利 用被缓存进内存的中间计算结果，在各个分区上多线 程的并行计算节省了大部分时间。

由于本文实验设 备条件有限，只搭建了三个 Slaver 计算节点，可预见 当增加计算节点的数量后，在进行更大数据量的实 验中算法的运行效率将会比传统算法有指数级 的 提升

### 12 13

本文提出一种基于Spark的并行随机森林算法

采用加权投票的方式提高随机森林算法的分类精度，并结合Spark并行化的特点，提出了利用数据索引抽样(DIS)和随机特征索引(RFI)的方法提高随机森林算法在Spark上并行化运行的效率。实验结果表明SP-RF算法无论是在分类精度还是运行时间上都比传统随机森林算法更胜一筹

在以后的研究中，将进一步对随机森林算法在特征选择、决策树之间相似度等方面进行改进从而提高随机森林算法的分类精度，并且结合Spark并行化的特点对随机森林算法进行优化，使随机森林算法在Spark平台上运行得更加高效

### 14

本次汇报到此结束，感谢聆听